{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://i.imgur.com/qpRACer.png />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import PIL\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Functions for Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawingModule = mp.solutions.drawing_utils\n",
    "handsModule = mp.solutions.hands\n",
    "mp_model = handsModule.Hands(static_image_mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_img(filePath, fileName, fileFormat):\n",
    "    \n",
    "    load_path = filePath + fileName + '.' + fileFormat\n",
    "    save_path = filePath + fileName\n",
    "    \n",
    "    return load_path, save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(fileName, mp_model):\n",
    "    \n",
    "    image = cv2.imread(fileName)\n",
    "    results = mp_model.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.multi_hand_landmarks != None:\n",
    "        for handLandmarks in results.multi_hand_landmarks:\n",
    "            drawingModule.draw_landmarks(image, handLandmarks, handsModule.HAND_CONNECTIONS, \n",
    "                                         drawingModule.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4), \n",
    "                                         drawingModule.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "                                        )\n",
    "\n",
    "        cv2.imshow(fileName, image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    img = PIL.Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    return img, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_detection(results):\n",
    "    \n",
    "    hand = 'none'\n",
    "\n",
    "    if len(results.multi_handedness) == 1:\n",
    "        if results.multi_handedness[0].classification[0].label == 'Left':\n",
    "            hand = 'left'\n",
    "        if results.multi_handedness[0].classification[0].label == 'Right':\n",
    "            hand = 'right'\n",
    "    else:\n",
    "        hand = 'both'\n",
    "\n",
    "    return hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(hand, results):\n",
    "    \n",
    "    kp_list = []\n",
    "    \n",
    "    if hand == 'right':\n",
    "        for i in range(0, 21):\n",
    "            kp_list.append([0, 0, 0])\n",
    "        \n",
    "        for data_point in results.multi_hand_landmarks[0].landmark:\n",
    "            kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "        \n",
    "    if hand == 'left':\n",
    "        for data_point in results.multi_hand_landmarks[0].landmark:\n",
    "            kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "        \n",
    "        for i in range(0, 21):\n",
    "            kp_list.append([0, 0, 0])\n",
    "    \n",
    "    if hand == 'both':\n",
    "        for data_point in results.multi_hand_landmarks[0].landmark:\n",
    "            kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "        \n",
    "        for data_point in results.multi_hand_landmarks[1].landmark:\n",
    "            kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "    \n",
    "    keypoints = np.array(kp_list)\n",
    "    \n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(csv_file):\n",
    "    \n",
    "    columns = ['letter']\n",
    "    \n",
    "    for val in range(1, 22):\n",
    "        columns += ['xl{}'.format(val), 'yl{}'.format(val), 'zl{}'.format(val)]\n",
    "    \n",
    "    for val in range(1, 22):\n",
    "        columns += ['xr{}'.format(val), 'yr{}'.format(val), 'zr{}'.format(val)]\n",
    "    \n",
    "    with open(csv_file, mode='w', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(letter, keypoints, csv_file):\n",
    "    \n",
    "    temp = list(keypoints.flatten())\n",
    "    temp.insert(0, letter)\n",
    "    \n",
    "    with open(csv_file, mode='a', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CSV file with Keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_path, save_path = input_img('', 'right', 'jpg')\n",
    "# img, results = mediapipe_detection(load_path, mp_model)\n",
    "# hand = hand_detection(results)\n",
    "# keypoints = extract_keypoints(hand, results)\n",
    "# write_csv('A', keypoints, 'features.csv')\n",
    "# np.save(save_path, keypoints)\n",
    "# np.load(save_path + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = 'A'\n",
    "# count = 97\n",
    "\n",
    "# for i in range(1, count):\n",
    "#     load_path, save_path = input_img('test/' + label + '/', label + str(i), 'jpg')\n",
    "#     img, results = mediapipe_detection(load_path, mp_model)\n",
    "#     hand = hand_detection(results)\n",
    "#     keypoints = extract_keypoints(hand, results)\n",
    "#     write_csv(label, keypoints, 'features.csv')\n",
    "#     np.save(save_path, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('features.csv')\n",
    "\n",
    "X = df.drop('letter', axis=1)\n",
    "y = df['letter']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Testing & Evaluation of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models['lr'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['lr'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Camera Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_model.pkl', 'rb') as f:\n",
    "    best_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while cam.isOpened():\n",
    "    \n",
    "    try:\n",
    "        ret, frame = cam.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        results = mp_model.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if results.multi_hand_landmarks != None:\n",
    "            for handLandmarks in results.multi_hand_landmarks:\n",
    "                drawingModule.draw_landmarks(image, handLandmarks, handsModule.HAND_CONNECTIONS, \n",
    "                                             drawingModule.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4), \n",
    "                                             drawingModule.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "                                            )\n",
    "        \n",
    "        hand = 'none'\n",
    "        \n",
    "        if len(results.multi_handedness) == 1:\n",
    "            if results.multi_handedness[0].classification[0].label == 'Left':\n",
    "                hand = 'left'\n",
    "            if results.multi_handedness[0].classification[0].label == 'Right':\n",
    "                hand = 'right'\n",
    "        else:\n",
    "            hand = 'both'\n",
    "        \n",
    "        \n",
    "        kp_list = []\n",
    "        \n",
    "        if hand == 'right':\n",
    "            for i in range(0, 21):\n",
    "                kp_list.append([0, 0, 0])\n",
    "            \n",
    "            for data_point in results.multi_hand_landmarks[0].landmark:\n",
    "                kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "        \n",
    "        if hand == 'left':\n",
    "            for data_point in results.multi_hand_landmarks[0].landmark:\n",
    "                kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "            \n",
    "            for i in range(0, 21):\n",
    "                kp_list.append([0, 0, 0])\n",
    "        \n",
    "        if hand == 'both':\n",
    "            for data_point in results.multi_hand_landmarks[0].landmark:\n",
    "                kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "            \n",
    "            for data_point in results.multi_hand_landmarks[1].landmark:\n",
    "                kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "        \n",
    "        keypoints = np.array(kp_list)\n",
    "        temp = list(keypoints.flatten())\n",
    "        \n",
    "        test = pd.DataFrame([temp])\n",
    "        hand_pred = best_model.predict(test)[0]\n",
    "        hand_prob = best_model.predict_proba(test)[0]\n",
    "        \n",
    "        cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "        cv2.putText(image, 'LETTER', (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, hand_pred.split(' ')[0], (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(image, 'PROB', (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(round(np.amax(hand_prob), 2)), (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    cv2.imshow('Camera Demonstration', image)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Image Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'a.jpg'\n",
    "image = cv2.imread(fileName)\n",
    "results = mp_model.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "if results.multi_hand_landmarks != None:\n",
    "    for handLandmarks in results.multi_hand_landmarks:\n",
    "        drawingModule.draw_landmarks(image, handLandmarks, handsModule.HAND_CONNECTIONS, \n",
    "                                     drawingModule.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4), \n",
    "                                     drawingModule.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "                                    )\n",
    "\n",
    "img = PIL.Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "hand = 'none'\n",
    "\n",
    "if len(results.multi_handedness) == 1:\n",
    "    if results.multi_handedness[0].classification[0].label == 'Left':\n",
    "        hand = 'left'\n",
    "    if results.multi_handedness[0].classification[0].label == 'Right':\n",
    "        hand = 'right'\n",
    "else:\n",
    "    hand = 'both'\n",
    "        \n",
    "\n",
    "kp_list = []\n",
    "\n",
    "if hand == 'right':\n",
    "    for i in range(0, 21):\n",
    "        kp_list.append([0, 0, 0])\n",
    "    \n",
    "    for data_point in results.multi_hand_landmarks[0].landmark:\n",
    "        kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "\n",
    "if hand == 'left':\n",
    "    for data_point in results.multi_hand_landmarks[0].landmark:\n",
    "        kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "    \n",
    "    for i in range(0, 21):\n",
    "        kp_list.append([0, 0, 0])\n",
    "\n",
    "if hand == 'both':\n",
    "    for data_point in results.multi_hand_landmarks[0].landmark:\n",
    "        kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "    \n",
    "    for data_point in results.multi_hand_landmarks[1].landmark:\n",
    "        kp_list.append([data_point.x, data_point.y, data_point.z])\n",
    "\n",
    "keypoints = np.array(kp_list)\n",
    "temp = list(keypoints.flatten())\n",
    "\n",
    "test = pd.DataFrame([temp])\n",
    "hand_pred = best_model.predict(test)[0]\n",
    "hand_prob = best_model.predict_proba(test)[0]\n",
    "\n",
    "cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "cv2.putText(image, 'LETTER', (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "cv2.putText(image, hand_pred.split(' ')[0], (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(image, 'PROB', (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "cv2.putText(image, str(round(np.amax(hand_prob), 2)), (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow(fileName, image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
